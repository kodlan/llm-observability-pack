# vLLM model configuration
MODEL_NAME=Qwen/Qwen2.5-1.5B-Instruct
VLLM_MAX_MODEL_LEN=2048
VLLM_GPU_MEMORY_UTILIZATION=0.8